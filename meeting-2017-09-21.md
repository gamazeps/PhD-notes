# Main topic

## Topic covered

Presentation of DeepVariant algorithm:

- Local realignment method
- Candidate variant location selection
- Transformation into a image
- Quick overview of the network architecture (just mentioned InceptionV2 as a CNN and locality
  properties)

Once Avinash left, Yanlei and I had a discussion about what was the expected process of a PhD, as
having not done a research internship I did not understand before.

## Topics not covered

- Transfer learning across species
- Retraining on different sequencers
- Computational cost
- Opportunities opened by DeepVariant

# Remarks on the presentation

The presentation lacked insights on:

- Why the transformation to an image made sense.
- Why pretraining on ImageNet dataset was done and made sense.
- What insights did DeepVariant get that other methods did not get (locality and covariance were
  mentioned in an unsatisfactory depth).
- The candidate emission phase was not clear enough (it was not clear that up to two candidates were
  emited per positions and that they were evaluated independently).
- The presentation lacked clear figures for the pipeline, which lead to poor clarity.

# Work for next week

- Presentation of the maths and insights of convolutional neural networks (@Avinash as your
  background is in physics you should have no problem following if I do a good job at presenting).
- Presentation of the insights of DeepVariant.
- Cover why transfer learning accross species work and the scalability of DeepVariant to various
  sequencing technologies.
- (admin): Order computer.

# General remarks

- Next week meeting will be done over Skype.
- The next two months will be focused on training me in understanding a topic in depth.
- My theoretical understanding of Data Processing should be taken care of by Yanlei's class.
- My theoretical understanding of deep learning will be tested during the next few weeks.
