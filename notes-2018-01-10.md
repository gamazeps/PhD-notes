# Variants data

I downloaded and unzipped the data from ncbi for the SVs with

```
wget -r ftp://ftp.ncbi.nlm.nih.gov/pub/dbVar/data/Homo_sapiens/by_study/estd219_1000_Genomes_Consortium_Phase_3_Integrated_SV/vcf/ 
```

Because the vcfs from the 1000gp ftp were at best unreadable (and the ones from were at best very
hard to understand).

Some numbers:

```
➜  vcf: cat estd219_1000_Genomes_Consortium_Phase_3_Integrated_SV.GRCh37.submitted.variant_call.germline.vcf | grep -i 'NA12878' | wc -l
3265
➜  vcf: cat estd219_1000_Genomes_Consortium_Phase_3_Integrated_SV.GRCh37.submitted.variant_call.germline.vcf | wc -l                    
8812590
```

The format of the data is:

```
➜  vcf: cat estd219_1000_Genomes_Consortium_Phase_3_Integrated_SV.GRCh37.submitted.variant_call.germline.vcf | grep -i 'NA12878' | head -n 1
1       2911537 essv16945607    A       <DEL:ME:ALU>    .       .  DBVARID;CALLID=DEL_pindel_91_NA12878;SVTYPE=DEL;EXPERIMENT=9;SAMPLE=NA12878;END=2911850;REGION=esv3818169
```

Which is very good for us.

One drawback is that there may be many duplicates in these SV if there are no SNPs or indels near
them, we will have to do some form of deduplication to know the actual number of variants.

Nevertheless it is good to see that we may have a *lot* of samples to train on ! Even by making a
conservative assuption that each SV is shared by 100 person with no SNPs nearby to differentiate
them we woul have ~8Ok samples.
