# Attention ! Attention !

Today is focused on the following tasks:

- Better understanding of attention models
- Polish up my SV calling review
- Finish up my CNN implementation

## Attention models

Same paper as Monday, except that this time I actually managed to read it (~1h), I will probably
need to read it a second time because the first part is rather dense.

Problem statement: Current multiple object detection tasks are extremely computationaly expensive
and are done using a sliding window and a CNN, this does not scale to large images.

Proposed solution: Use a small CNN that works on `glimpses` of the image and have an RNN select the
glimpses to look at (the attention part).

The reason why they use an attention model is because most current approachs used a separately
trained sequence detector or a bottom up proposal generator and the authors wanted to improve on
that part.

*Note*: The proposal generator might be interesting in variant calling as it is currently done using
a heuristic (a good one, but a bottom-up, stateless, approach nevertheless).

The networks work as follow:

- A Glimpse networks, that takes the image and location as inputs and output a vetor representation
  of the location (3 layers CNN).
- A Reccurent network with two recurrent layers, one for the internal state and one for the
  candidate location.
- A context network used at the beginning on a downsampled version of the image to extract
  structural information (optional).
- Clasification network, a FC layer working on the hidden state of the Recurrent network.

The math behind the learning are a bit tricky for me right now, they apparentlt optimised on the
free energy (no idea what that is), and then used a few approximation to compute the gradient (some
Monte Carlo which I believe is just the reformulation of SGD and another trick for the prediction).

*Note*: The function that they optimized for was derived without using RL algorithm and yet can
still be stated as an RL problem where the RNN works as an axploration policy (there is an
hyperparameter there, the variance $\sigma$ of the gaussian they used for MC).  
That is interesting because it shows that RL can be expressed directly as a learning task.

In addition their architecture is trained for ordered sequence of object detection, this is
something we do not care for in variant calling, relaxing that constraint might give better results
for us.

### Why do we care ?

First of all the results are better than the state of the art at the time, not by much but that is
still a reason to care (3.96 vs 3.9 on street view numbers).

In my opinion the interesting part is that their architecture can work on images of all sizes, where
non retrained CNNs cannot do that. Hence it "learns" more than they do as they are able to
generalize.

Furthermore they used significantly less parameters and FLOPS than CNNs architectures (3-4x less
Flops and 2-8x less parameters). The number of parameters is independant of the size of the image
which is a great property. This also means much lower raining time (hours vs days).

*Note* they compared to regular CNNs and not to Inception, known to have much less parameters
and FLOPs, so the comparaison may not be fair.

### Plan for the future

It would be nice to read on "attention is all you need" and the Mnih paper (Reccurrent models of
visual attention) which introduces the Recurrent Attention Model (RAM).

## Making the difference: integrating structural variant callers

This review presents what structural variants are, what kind of SVs exist, the main strategies to
find them and how it is done un practice

### Types of SV

- imabalanced: also called CNVs, deletions, duplication or insertions (transposons for example).
- balanced: inversion or translocations.

### Types of methods to find them

The range of genomic data can be smaller than WGS by resequencing regions of interest.

- AS: uses unaligned reads directly and tries to realign them locally (mostly by building contig
  graphs). Single base pair precision for breakpoint resolution, but bad for inversions.
- RD/RC: uses aligned reads and counts their frequency, deletions and duplications.
- SR: uses aligned paired end reads, aligns one end and sees where the other one falls in the
  genome (can clip one end).
- RP: uses aligned reads and aligns both ends of the read, calls an indel if the paired reads are
  aligned too close or two far apart (>2 std, relative to the mean distance).

### Pipelines

Many callers exist, previously they used only one signal (and thus tradeoffs were made in terms of
the type of variants they can call). Recently they are starting to use multiple signals, the first
one for finding candidates, the second one for refining the calls.

The current strategy is to merge the results of multiple callers. We can try either to have little
overlap between the calls and thus simply do a union of their calls, or if they have overlap do a
voting strategy.

The merge part was improvalble at the moment the paper was published, indeed choosing which signals
to use was a problem (using 19 callers, 5 were responsible for 50% of the calls the other can be
considered not efficient). Furthermore the merge strategies had not been formalised, it was either
done by counting how many callers called a variant (>=2 and the variant was called), or done by
providing empiric confidence in each callers. 

Population information also tends to be used for calling rarer variants.

### Opportunities

The current lack of gold standard currently impeads proper benchmarking, the [Dream challenges](
https://www.synapse.org/#!Synapse:syn2813589/wiki/401435) provide some hope in this area and can be
an opportunity to showcase new algorithms.

Formal statistical work can be done in two areas:

- Improving merging strategies by either ensemble methods or Kalman Filters.
- Improving the use of different signals by either merging their calls with kalman filters or by
  using signals with high sensitivity and poor specificity to call candidates for deeper analysis
  with more specific methods (or more computationaly expensive).

Having statisticaly robust selection of the callers used in a pipeline could be used to improve the
ressource efficiency of variant calling.

Working on a better calling strategy could lower latency.

*Note*: it is interesting to see that population information is also used here as in SNVs calling,
maybe forgetting it as deep varaiant does could improve the results, provided we see enough data.

In my opinion the biggest problem with these models (only skimmed Pindel and Delly) is that the
model they use have little approximation power. This may not have been a problem before because they
are very efficient with their parameters, but it might be worth it to investigate methods with
orders of magnitude more parameters (with much lower parameter efficiency) as data is available
here.
